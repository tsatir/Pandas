{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sklearn.neighbors.KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sklearn.neighbors.KNeighborsRegressor(n_neighbors=5, weights='uniform', algorithm='auto', leaf_size=30, p=2, metric='minkowski', metric_params=None, n_jobs=None, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- n_neighbors : number of neighbors, different k's can be tried and chosen for best accuracy results\n",
    "- weights : \n",
    "    - uniform (default) -> all points weighted equally like 1 unit change is same for all data points\n",
    "    - distance -> closer neighbors will have greater influence.\n",
    "- algorithm : ball_tree, kd_tree, brute and auto can be selected. Auto is default.\n",
    "- metric : distance, default is minkowski distance which is special form of euclidean and manhattan distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using same data from house_prices_df\n",
    "\n",
    "dict_list = {}\n",
    "for i in range(1,10):\n",
    "    knn = neighbors.KNeighborsRegressor(n_neighbors = i)\n",
    "    knn.fit(X_train, y_train)\n",
    "    score = cross_val_score(knn, X_test, y_test, cv=5)\n",
    "    score_r = round(score.mean(),3)\n",
    "    dict_list[i] = score_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(list(dict_list.keys()),list(dict_list.values()))\n",
    "plt.xticks(range(1, 10))\n",
    "plt.xlabel(\"k\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import neighbors\n",
    "\n",
    "# Build our model.\n",
    "knn = neighbors.KNeighborsRegressor(n_neighbors = 5, weights = 'distance')\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "y_preds_train = knn.predict(X_train)\n",
    "y_preds_test = knn.predict(X_test)\n",
    "\n",
    "R_sqr = knn.score(X_train, y_train)\n",
    "R_sqr_test = knn.score(X_test, y_test)\n",
    "mae_test = mean_absolute_error(y_test, y_preds_test)\n",
    "mse_test = mse(y_test, y_preds_test)\n",
    "rmse_test = rmse(y_test, y_preds_test)\n",
    "\n",
    "score = cross_val_score(knn, X_test, y_test, cv=5)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (score.mean(), score.std() * 2))\n",
    "\n",
    "\n",
    "print(\"R-squared of the model in training set is: {}\".format(R_sqr))\n",
    "print(\"-----Test set statistics-----\")\n",
    "print(\"R-squared of the model in test set is: {}\".format(R_sqr_test))\n",
    "print(\"Mean absolute error of the prediction is: {}\".format(mae_test))\n",
    "print(\"Mean squared error of the prediction is: {}\".format(mse_test))\n",
    "print(\"Root mean squared error of the prediction is: {}\".format(rmse_test))\n",
    "print(\"Mean absolute percentage error of the prediction is: {}\".format(np.mean(np.abs((y_test - y_preds_test) / y_test)) * 100))\n",
    "\n",
    "results_data.append(['Knn_regressor', R_sqr, R_sqr_test, mae_test, mse_test, rmse_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results showed that ols has better accuracy than knn regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
